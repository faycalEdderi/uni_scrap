# ğŸ­ Fandom Explorer

Une application complÃ¨te de scraping et d'exploration des wikis Fandom, dÃ©veloppÃ©e dans le cadre d'un projet universitaire.

## ğŸ“‹ Description

Fandom Explorer est une solution complÃ¨te permettant de :
- **Scraper automatiquement** n'importe quel wiki Fandom
- **Extraire intelligemment** les donnÃ©es de personnages/objets avec images
- **Visualiser et explorer** les donnÃ©es dans une interface moderne
- **Comparer** les personnages cÃ´te Ã  cÃ´te

## ğŸ¥ DÃ©monstration VidÃ©o

DÃ©couvrez le fonctionnement complet de l'application dans cette vidÃ©o de prÃ©sentation :

<video width="100%" controls>
  <source src="scrapper.mp4" type="video/mp4">
  Votre navigateur ne supporte pas la balise vidÃ©o.
</video>

*La vidÃ©o prÃ©sente le scraping en temps rÃ©el, l'interface utilisateur et les fonctionnalitÃ©s de comparaison.*

**Alternative** : Si la vidÃ©o ne s'affiche pas correctement, vous pouvez la tÃ©lÃ©charger directement : [scrapper.mp4](./scrapper.mp4)

## ğŸš€ FonctionnalitÃ©s

### ğŸ” Scraper GÃ©nÃ©rique
- Support universel pour tous les wikis Fandom
- Extraction automatique des informations :
  - âœ… Nom du personnage
  - âœ… Image principale (obligatoire)
  - âœ… Description/biographie
  - âœ… Type/RÃ´le/Classe
  - âœ… 2+ attributs spÃ©cifiques (pouvoir, affiliation, etc.)
- Gestion robuste des erreurs et des structures variÃ©es
- Export en JSON structurÃ©
- Rapports de scraping dÃ©taillÃ©s

### ğŸ¨ Interface Frontend
- **Page d'accueil** avec barre de recherche pour URL Fandom
- **Page d'exploration** avec cartes de personnages interactives
- **SystÃ¨me de recherche** avec autocomplÃ©tion
- **Comparateur** de personnages cÃ´te Ã  cÃ´te
- **Design responsive** et animations fluides
- **Interface moderne** avec effets de blur et dÃ©gradÃ©s

## ğŸ“ Structure du Projet

```
uni_scrap/
â”œâ”€â”€ scraper/                    # Code de scraping Scrapy
â”‚   â”œâ”€â”€ fandom_scrap/          # Projet Scrapy principal
â”‚   â”‚   â”œâ”€â”€ spiders/           # Spider gÃ©nÃ©rique Fandom
â”‚   â”‚   â”œâ”€â”€ items.py           # Structure des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ pipelines.py       # Traitement et validation
â”‚   â”‚   â””â”€â”€ settings.py        # Configuration Scrapy
â”‚   â”œâ”€â”€ run_scraper.py         # Script de lancement simple
â”‚   â””â”€â”€ test_fandoms.py        # Tests automatiques
â”œâ”€â”€ frontend/                  # Application React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # Composants React
â”‚   â”‚   â”œâ”€â”€ App.js            # Application principale
â”‚   â”‚   â””â”€â”€ App.css           # Styles globaux
â”‚   â””â”€â”€ public/               # Fichiers statiques
â”œâ”€â”€ data/                     # DonnÃ©es extraites (JSON)
â”œâ”€â”€ tested_fandoms.txt        # Liste des fandoms testÃ©s
â””â”€â”€ README.md                # Documentation
```

## âš™ï¸ Installation et Utilisation

### PrÃ©requis
- Python 3.8+ avec environnement virtuel
- Node.js 16+
- Git

### ğŸ Configuration du Scraper

1. **Activer l'environnement virtuel Python**
```bash
cd scraper
# Activer votre environnement virtuel existant
```

2. **Lancer un scraping**
```bash
# Scraper un fandom spÃ©cifique
python run_scraper.py https://leagueoflegends.fandom.com/ --max-pages 100

# Ou directement avec Scrapy
cd fandom_scrap
scrapy crawl fandom -a fandom_url=https://pokemon.fandom.com/ -a max_pages=50
```

3. **Tester plusieurs fandoms automatiquement**
```bash
python test_fandoms.py
```

### âš›ï¸ Configuration du Frontend

1. **Installer les dÃ©pendances**
```bash
cd frontend
npm install
```

2. **Lancer l'application**
```bash
npm start
```

L'application sera accessible sur `http://localhost:3000`

## ğŸ§ª Fandoms TestÃ©s

Le scraper a Ã©tÃ© testÃ© avec succÃ¨s sur plus de 20 fandoms diffÃ©rents :

- **Gaming** : League of Legends, Overwatch, Genshin Impact, Minecraft
- **Anime/Manga** : One Piece, Naruto, Dragon Ball
- **Films/SÃ©ries** : Star Wars, Harry Potter, Marvel
- **Et bien d'autres...**

Voir `tested_fandoms.txt` pour la liste complÃ¨te.

## ğŸ› ï¸ Choix Techniques

### Backend (Scraper)
- **Scrapy** : Framework robuste pour le web scraping
- **Python** : Langage polyvalent avec excellentes librairies
- **JSON** : Format d'export universel et facilement exploitable
- **Architecture modulaire** : Pipelines de validation et traitement

**Justification** : Scrapy offre une gestion native des requÃªtes asynchrones, retry automatique, respect du robots.txt, et une architecture extensible parfaite pour un scraper universel.

### Frontend
- **React** : Framework moderne avec Ã©cosystÃ¨me riche
- **Styled-Components** : CSS-in-JS pour des composants modulaires
- **Framer Motion** : Animations fluides et professionnelles
- **React Router** : Navigation entre les pages

**Justification** : React permet une interface utilisateur rÃ©active et moderne, tandis que styled-components offre une approche component-based pour le styling.

## ğŸ“Š Gestion des Erreurs

### Scraper
- **Validation des URLs** : VÃ©rification du format Fandom
- **Retry automatique** : En cas d'Ã©chec rÃ©seau
- **Fallbacks intelligents** : SÃ©lecteurs multiples pour chaque donnÃ©e
- **Logs dÃ©taillÃ©s** : TraÃ§abilitÃ© complÃ¨te des erreurs
- **Validation des images** : VÃ©rification de l'existence et du format

### Frontend
- **Gestion des Ã©tats de chargement** : Indicators visuels
- **Fallbacks pour images** : Placeholders en cas d'erreur
- **Messages d'erreur explicites** : Pour guider l'utilisateur
- **Navigation gracieuse** : Redirections automatiques

## ğŸ¯ Optimisations et Robustesse

### Performance
- **RequÃªtes asynchrones** : Scraping parallÃ¨le intelligent
- **Throttling respectueux** : DÃ©lais entre requÃªtes
- **Cache intelligent** : Ã‰vite les doublons
- **Lazy loading** : Chargement progressif dans l'interface

### AdaptabilitÃ©
- **SÃ©lecteurs multiples** : Pour s'adapter aux structures variÃ©es
- **DÃ©tection automatique** : Types de contenus et structures
- **Configuration flexible** : ParamÃ¨tres ajustables par fandom
- **ExtensibilitÃ©** : Architecture modulaire pour ajouts futurs

## ğŸ“ˆ MÃ©triques de SuccÃ¨s

- **20+ fandoms** supportÃ©s avec extraction complÃ¨te
- **90%+ de taux de rÃ©ussite** sur l'extraction d'images
- **Temps de scraping optimisÃ©** : ~1-2 secondes par page
- **Interface responsive** : Support mobile et desktop
- **Code maintenable** : Architecture claire et documentÃ©e

## ğŸ”® AmÃ©liorations Futures

- **API REST** : Pour exposer les donnÃ©es scrapÃ©es
- **Base de donnÃ©es** : Stockage persistant avec PostgreSQL
- **Scraping incrÃ©mental** : Mise Ã  jour uniquement des nouveautÃ©s
- **Machine Learning** : Classification automatique des personnages
- **PWA** : Application web progressive avec mode offline

## ğŸ‘¥ Contribution

Ce projet est dÃ©veloppÃ© dans le cadre acadÃ©mique. Pour toute suggestion ou amÃ©lioration :

1. Fork le projet
2. CrÃ©er une branche feature
3. Commit les changements
4. Push vers la branche
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Projet universitaire - Ã€ des fins Ã©ducatives uniquement.

---

**DÃ©veloppÃ© par Mouad Aoughane et Faycal Edderi pour IPSSI**
